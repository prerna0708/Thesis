{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f2f27a6",
   "metadata": {},
   "source": [
    "# Data collection and data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891df129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e40d156",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_13f_filings(start=0):\n",
    "    start=0\n",
    "    x=0\n",
    "    while start<100000:\n",
    "            print(f\"Getting next 13F batch starting at {start}\") \n",
    "            query={\n",
    "                \"query\": { \"query_string\": { \n",
    "                    \"query\": \"formType:\\\"13F-HR\\\" AND NOT formType:\\\"13F-HR/A\\\" AND periodOfReport:\\\"2021-12-31\\\"\" \n",
    "                    } },\n",
    "                \"from\": start,\n",
    "                \"size\": \"250\",\n",
    "                \"sort\": [{ \"filedAt\": { \"order\": \"desc\" } }]\n",
    "            }\n",
    "            response = queryApi.get_filings(query)\n",
    "            if x==0:\n",
    "                filings_batch=pd.json_normalize(response['filings'])\n",
    "            else:\n",
    "                z=pd.json_normalize(response['filings'])\n",
    "                if (z.empty):\n",
    "                    break\n",
    "                filings_batch=pd.concat((filings_batch, z), axis = 0,ignore_index=True)\n",
    "                #filings_batch=filings_batch.append(z,ignore_index = True)\n",
    "            x=x+1\n",
    "            start=start+200\n",
    "            \n",
    "    return filings_batch\n",
    "\n",
    "def split_dataframe(df, chunk_size = 1000): \n",
    "    chunks = list()\n",
    "    num_chunks = len(df) // chunk_size + 1\n",
    "    for i in range(num_chunks):\n",
    "        chunks.append(df[i*chunk_size:(i+1)*chunk_size])\n",
    "    return chunks\n",
    "\n",
    "def Extracting_holdings(Filing):\n",
    "    #filings_batch=Filing\n",
    "    Filing=Filing[Filing['holdings'].notna()].reset_index(drop=True)\n",
    "    for x in range(len(Filing)):  \n",
    "        holdings_ = pd.json_normalize(Filing['holdings'][x])\n",
    "        holdings_['id'] = Filing['id'][x]\n",
    "        holdings_['cik'] = Filing['cik'][x]\n",
    "        holdings_['companyName']=Filing['companyName']\n",
    "        if x==0:\n",
    "            Holdings= pd.DataFrame(columns=holdings_.columns)\n",
    "        else:\n",
    "            Holdings=pd.concat((Holdings, holdings_), axis = 0,ignore_index=True)\n",
    "    return Holdings\n",
    "\n",
    "def Holdings(df):\n",
    "    for x in range(len(df)):\n",
    "        print(x)\n",
    "        Hold_try=Extracting_holdings(df[x])\n",
    "        if x==0:\n",
    "            Hold_final=Hold_try\n",
    "        else:\n",
    "            Hold_final=pd.concat((Hold_final, Hold_try), axis = 0,ignore_index=True)\n",
    "            #Hold_final=Hold_final.append(Hold_try,ignore_index = True)\n",
    "    return Hold_final\n",
    "\n",
    "def cik_(df):\n",
    "    for x in range(len(df)):\n",
    "        print(x)\n",
    "        w=df[x].reset_index()\n",
    "        for y in range(len(df[x])):\n",
    "            a=pd.DataFrame((w[\"cik\"][y]).split(\":\"))\n",
    "            z=a.transpose()\n",
    "            if y==0:\n",
    "                cik=z\n",
    "            else:\n",
    "                cik=pd.concat((cik, z), axis = 0,ignore_index=True)\n",
    "                #cik=cik.append(z, ignore_index=True)\n",
    "        if x==0:\n",
    "            cik_final=cik\n",
    "        else:\n",
    "            cik_final=pd.concat((cik_final, cik), axis = 0,ignore_index=True)\n",
    "            #cik_final=cik_final.append(cik, ignore_index=True)\n",
    "    return cik_final\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12897bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_13f_HRA_filings(start=0):\n",
    "    start=0\n",
    "    x=0\n",
    "    while start<100000:\n",
    "            print(f\"Getting next 13F batch starting at {start}\") \n",
    "            query={\n",
    "                \"query\": { \"query_string\": { \n",
    "                    \"query\": \"formType:\\\"13F-HR/A\\\" AND periodOfReport:\\\"2021-12-31\\\"\" \n",
    "                    } },\n",
    "                \"from\": start,\n",
    "                \"size\": \"250\",\n",
    "                \"sort\": [{ \"filedAt\": { \"order\": \"desc\" } }]\n",
    "            }\n",
    "            response = queryApi.get_filings(query)\n",
    "            if x==0:\n",
    "                filings_batch=pd.json_normalize(response['filings'])\n",
    "            else:\n",
    "                z=pd.json_normalize(response['filings'])\n",
    "                if (z.empty):\n",
    "                    break\n",
    "                    \n",
    "                filings_batch=filings_batch.append(z,ignore_index = True)\n",
    "            x=x+1\n",
    "            start=start+200\n",
    "            \n",
    "    return filings_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c76f92",
   "metadata": {},
   "source": [
    "# Fetching data from \"www.sec.gov\"\n",
    "\n",
    "Write your email address in the place of 'abc@gmail.com' in statement: headers = {'User-Agent': 'abc@gmail.com'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb26b689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_13hra(link):\n",
    "    conn = http.client.HTTPSConnection(\"www.sec.gov\")\n",
    "    payload = ''\n",
    "    headers = {'User-Agent': 'abc@gmail.com'}\n",
    "    conn.request(\"GET\", link, payload, headers)\n",
    "    res = conn.getresponse()\n",
    "    data = res.read()\n",
    "    c=data.decode(\"utf-8\")\n",
    "    df = pd.read_xml(c)\n",
    "    return df\n",
    "\n",
    "def fetch_url(Filings_HR_A):\n",
    "    for x in range(len(Filings_HR_A)):  \n",
    "        XML_url = pd.json_normalize(Filings_HR_A[\"documentFormatFiles\"][x])\n",
    "        XML_url['cik'] = Filings_HR_A['cik'][x]\n",
    "        XML_url[\"filedAt\"]=Filings_HR_A[\"filedAt\"][x]\n",
    "        if x==0:\n",
    "            url_table= pd.DataFrame(columns=XML_url.columns)\n",
    "            url_table=XML_url\n",
    "        else:\n",
    "            url_table=pd.concat((url_table,XML_url), axis=0, ignore_index=True)\n",
    "           #url_table=url_table.append(XML_url,ignore_index = True)\n",
    "    url_tbl_final=url_table[(url_table[\"type\"]==\"INFORMATION TABLE\") & (url_table[\"sequence\"]==\"2\")].iloc[1::2, :]\n",
    "    return url_tbl_final\n",
    "        \n",
    "def fetch_data_from_xml(url_tbl_final):\n",
    "    for x in range(len(url_tbl_final)):\n",
    "        link=url_tbl_final[\"documentUrl\"].iloc[x]\n",
    "        df=fetch_13hra(link)\n",
    "        df[\"cik\"]=url_tbl_final[\"cik\"].iloc[x]\n",
    "        if x==0:\n",
    "            hr_a_filings=df\n",
    "        else:\n",
    "            hr_a_filings=pd.concat((hr_a_filings, df), axis = 0,ignore_index=True)\n",
    "    return hr_a_filings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6456b4c",
   "metadata": {},
   "source": [
    "# Regular expressions to correct the names for joining with CIK table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310e2b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformation_v1(df,x):\n",
    "    df[x]=df[x].str.upper()\n",
    "    df[x]=df[x].replace(to_replace =',|\\.|\\/|-|', value = '', regex = True).str.strip()   \n",
    "    df[x]=df[x].replace('HOLDINGS|HOLDING|HLDGS','HLDG', regex=True)\n",
    "    df[x]=df[x].replace('INCORPORATED|INC','IN', regex=True)\n",
    "    df[x]=df[x].replace('INDUSTRIES|INSTRS|INDUSTRY','IND', regex=True)\n",
    "    df[x]=df[x].replace('COMPANY|COS','CO', regex=True)\n",
    "    df[x]=df[x].replace('CORPORATION','CORP', regex=True)\n",
    "    df[x]=df[x].replace('GROUP|GROUPS|GRPS','GRP', regex=True)\n",
    "    df[x]=df[x].replace('FUNDS|FUND','FDS', regex=True)\n",
    "    df[x]=df[x].replace('TRUST|TRUSTS','TR', regex=True)\n",
    "    #df[x]=df[x].replace('INDUSTRIES|INDUSTRY','INSTRS', regex=True)\n",
    "    df[x]=df[x].replace('SOUTHERN|SOUTHN','STHN', regex=True)\n",
    "    df[x]=df[x].replace('BOND|BONDS','BD', regex=True)\n",
    "    df[x]=df[x].replace('WHOLESALE','WHSL', regex=True)\n",
    "    df[x]=df[x].replace('LABORATORIES|LABORATORY','LABS', regex=True)\n",
    "    df[x]=df[x].replace('BANK','BK', regex=True)\n",
    "    df[x]=df[x].replace('EXCHANGE','EXCH', regex=True)\n",
    "    return df[x]\n",
    "\n",
    "def transformation_v2(df,x):\n",
    "    df[x]=df[x].replace(to_replace =',|\\.|\\/|-|COM|IRELAND|(THE)|(NEW)|LP|US LF ETF|COM CL A|SHS|CL|ADR UK UNITED|ADR|IE IRELAND|CH|SWITZERLAND|SPONS ADR|SHSISIN#BMG4593F1041|ORD SHS|SA BEARER AND ADR|ETF|EFT|UTD UK', value = '', regex = True).str.strip()\n",
    "    # Hold_final[x].replace('INCORPORATED','INC')\n",
    "    df[x]=df[x].replace('COS','CO', regex=True).str.strip()\n",
    "    df[x]=df[x].replace('CAPITAL','CAP', regex=True).str.strip()\n",
    "    df[x]=df[x].replace('INTERNATIONAL','INTL', regex=True).str.strip()\n",
    "    df[x]=df[x].replace('INCS','INC', regex=True).str.strip()\n",
    "    df[x]=df[x].replace('TECHNOLOGY|TECHNOLOGIES','TECH', regex=True).str.strip()\n",
    "    return df[x]\n",
    "\n",
    "def transformation_v3(df,x):\n",
    "    df[x]=df[x].replace(to_replace =',|\\.|\\/|-|COM|IRELAND|CO|CORP|INC|IN|IN ASS A|S&P 500|IN  USD001  A| S&P 500 VALUE|EA REPR 5 ORD US|LIMITED|LTD|IN B|SPON|IN A|EUR001|', value = '', regex = True).str.strip()\n",
    "    df[x]=df[x].replace('SYSTEMS|SYSTEM','SYS', regex=True).str.strip()\n",
    "    df[x]=df[x].replace('WORKS','WKS', regex=True).str.strip()\n",
    "    df[x]=df[x].replace('NATIONAL','NATL', regex=True).str.strip()\n",
    "    df[x]=df[x].replace('FINANCIAL','FINL', regex=True).str.strip()\n",
    "    return df[x]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c279e7e7",
   "metadata": {},
   "source": [
    "# Creation of Nodes and Relationships for graph creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0d0ecd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Nodes_(Holdings,Filings):\n",
    "    import pandas as pd\n",
    "    Nodes=Filings[[\"companyName_unchanged\",\"cik\"]].drop_duplicates()\n",
    "    append=Holdings[[\"nameOfIssuer_unchanged\",\"CIK\"]].drop_duplicates()\n",
    "    Nodes.columns=[\"companyName\",\"cik\"]\n",
    "    append.columns=[\"companyName\",\"cik\"]\n",
    "    \n",
    "    Nodes=pd.concat((Nodes,append), axis=0,ignore_index=True)\n",
    "    Nodes=Nodes.drop_duplicates()\n",
    "    \n",
    "    Nodes['cik']=Nodes[\"cik\"].astype(int).astype(str)\n",
    "    Nodes['cik']=Nodes['cik'].str.lstrip(\"0\").str.rstrip(\"0\")\n",
    "    \n",
    "    Minus=Nodes[Nodes.duplicated('cik', keep=\"first\")]\n",
    "    Nodes=Nodes.drop(Minus.index).reset_index(drop=True)\n",
    "  \n",
    "    duplicates_company_name=Nodes[Nodes.duplicated('companyName',keep=False)].sort_values(\"companyName\") #can I change them manually in Holdings,Filings and then make relationships, nodes?\n",
    "\n",
    "    duplicates_company_name[\"companyName\"]=duplicates_company_name[\"companyName\"].str.cat(duplicates_company_name[[\"cik\"]].astype(str), sep=\"_\")\n",
    "    \n",
    "    Minus=duplicates_company_name\n",
    "    Nodes=Nodes.drop(Minus.index).reset_index(drop=True)\n",
    "    Nodes=pd.concat((Nodes,duplicates_company_name), axis=0, ignore_index=True)\n",
    "    \n",
    "    return Nodes,duplicates_company_name\n",
    "\n",
    "def Relationships_(Holdings):\n",
    "    Relationships=Holdings[[\"cusip\",\"cik_Filing\",\"titleOfClass\",\"putCall\",\"CIK\",\"investmentDiscretion\",\"value\",\"nameOfIssuer_unchanged\"]].drop_duplicates()\n",
    "    Relationships[\"CIK\"]=Relationships[\"CIK\"].astype(int).astype(str)\n",
    "    Relationships[\"CIK\"]=Relationships[\"CIK\"].str.lstrip(\"0\").str.rstrip(\"0\")\n",
    "    Relationships[\"cik_Filing\"]=Relationships[\"cik_Filing\"].astype(int).astype(str)\n",
    "    Relationships[\"cik_Filing\"]=Relationships[\"cik_Filing\"].str.lstrip(\"0\").str.rstrip(\"0\")\n",
    "    return Relationships"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
